{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20547b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "import ta\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, StepLR\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from skorch import NeuralNetClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fd7af11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "data = yf.download(\n",
    "    \"SPY\",\n",
    "    start=\"1990-01-01\",\n",
    "    end=\"2021-01-01\",\n",
    "    auto_adjust = True,\n",
    "    group_by=\"Ticker\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbe942f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/qingweilan/.pyenv/versions/3.8.12/lib/python3.8/site-packages/ta/trend.py:768: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dip[i] = 100 * (self._dip[i] / self._trs[i])\n",
      "/Users/qingweilan/.pyenv/versions/3.8.12/lib/python3.8/site-packages/ta/trend.py:772: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  din[i] = 100 * (self._din[i] / self._trs[i])\n"
     ]
    }
   ],
   "source": [
    "df = ta.utils.dropna(data)\n",
    "df = ta.add_all_ta_features(df, \"Open\", \"High\", \"Low\", \"Close\", \"Volume\", fillna=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5398d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setlabel(row):\n",
    "    return 1 if row['next_diff_curr'] >= 0 else 0\n",
    "\n",
    "df['next_diff_curr'] = df['Close'].shift(-1) - df['Close']\n",
    "df['label'] = df.apply(setlabel, axis=1)\n",
    "\n",
    "df['feature_sma_diff'] = df['trend_sma_fast'] - df['trend_sma_slow']\n",
    "df['feature_ema_diff'] = df['trend_ema_fast'] - df['trend_ema_slow']\n",
    "df['feature_diff_bbl'] = df['Close'] - df['volatility_bbl']\n",
    "df['feature_diff_bbh'] = df['volatility_bbh'] - df['Close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ad395c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Open', 'High', 'Low', 'Close', 'Volume', 'volume_adi', 'volume_obv',\n",
       "       'volume_cmf', 'volume_fi', 'volume_mfi', 'volume_em', 'volume_sma_em',\n",
       "       'volume_vpt', 'volume_nvi', 'volume_vwap', 'volatility_atr',\n",
       "       'volatility_bbm', 'volatility_bbh', 'volatility_bbl', 'volatility_bbw',\n",
       "       'volatility_bbp', 'volatility_bbhi', 'volatility_bbli',\n",
       "       'volatility_kcc', 'volatility_kch', 'volatility_kcl', 'volatility_kcw',\n",
       "       'volatility_kcp', 'volatility_kchi', 'volatility_kcli',\n",
       "       'volatility_dcl', 'volatility_dch', 'volatility_dcm', 'volatility_dcw',\n",
       "       'volatility_dcp', 'volatility_ui', 'trend_macd', 'trend_macd_signal',\n",
       "       'trend_macd_diff', 'trend_sma_fast', 'trend_sma_slow', 'trend_ema_fast',\n",
       "       'trend_ema_slow', 'trend_adx', 'trend_adx_pos', 'trend_adx_neg',\n",
       "       'trend_vortex_ind_pos', 'trend_vortex_ind_neg', 'trend_vortex_ind_diff',\n",
       "       'trend_trix', 'trend_mass_index', 'trend_cci', 'trend_dpo', 'trend_kst',\n",
       "       'trend_kst_sig', 'trend_kst_diff', 'trend_ichimoku_conv',\n",
       "       'trend_ichimoku_base', 'trend_ichimoku_a', 'trend_ichimoku_b',\n",
       "       'trend_visual_ichimoku_a', 'trend_visual_ichimoku_b', 'trend_aroon_up',\n",
       "       'trend_aroon_down', 'trend_aroon_ind', 'trend_psar_up',\n",
       "       'trend_psar_down', 'trend_psar_up_indicator',\n",
       "       'trend_psar_down_indicator', 'trend_stc', 'momentum_rsi',\n",
       "       'momentum_stoch_rsi', 'momentum_stoch_rsi_k', 'momentum_stoch_rsi_d',\n",
       "       'momentum_tsi', 'momentum_uo', 'momentum_stoch',\n",
       "       'momentum_stoch_signal', 'momentum_wr', 'momentum_ao', 'momentum_kama',\n",
       "       'momentum_roc', 'momentum_ppo', 'momentum_ppo_signal',\n",
       "       'momentum_ppo_hist', 'others_dr', 'others_dlr', 'others_cr', 'label',\n",
       "       'feature_sma_diff', 'feature_ema_diff', 'feature_diff_bbl',\n",
       "       'feature_diff_bbh'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(columns=['next_diff_curr'])\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "41daea9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed = df[84:]\n",
    "\n",
    "cols = set(df.columns)\n",
    "cols.remove('label')\n",
    "cols = list(cols)\n",
    "X = processed[cols].values\n",
    "y = processed[['label']].values.squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1d78b7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.astype(np.float32)\n",
    "y = y.astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "35b4628e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StockPredictor(nn.Module):\n",
    "\n",
    "    def __init__(self, feature_size):\n",
    "        super(StockPredictor, self).__init__()\n",
    "        self.m1 = nn.Sequential(\n",
    "            nn.Linear(feature_size, 256),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(128, 2),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.m1(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "62fc142c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6919\u001b[0m       \u001b[32m0.5482\u001b[0m        \u001b[35m0.6893\u001b[0m  0.2954\n",
      "      2        \u001b[36m0.6891\u001b[0m       0.5482        \u001b[35m0.6886\u001b[0m  0.2668\n",
      "      3        \u001b[36m0.6887\u001b[0m       0.5482        0.6887  0.2637\n",
      "      4        0.6888       0.5482        0.6887  0.2655\n",
      "      5        \u001b[36m0.6887\u001b[0m       0.5482        0.6887  0.2659\n",
      "      6        \u001b[36m0.6887\u001b[0m       0.5482        0.6887  0.2627\n",
      "      7        \u001b[36m0.6887\u001b[0m       0.5482        0.6887  0.2621\n",
      "      8        \u001b[36m0.6887\u001b[0m       0.5482        0.6887  0.2640\n",
      "      9        \u001b[36m0.6886\u001b[0m       0.5482        0.6887  0.2628\n",
      "     10        \u001b[36m0.6886\u001b[0m       0.5482        0.6887  0.2625\n",
      "     11        \u001b[36m0.6885\u001b[0m       0.5482        0.6887  0.2627\n",
      "     12        \u001b[36m0.6885\u001b[0m       0.5482        0.6887  0.2655\n",
      "     13        \u001b[36m0.6885\u001b[0m       0.5482        0.6887  0.2643\n",
      "     14        \u001b[36m0.6884\u001b[0m       0.5482        0.6886  0.2626\n",
      "     15        \u001b[36m0.6884\u001b[0m       0.5482        0.6886  0.2670\n",
      "     16        \u001b[36m0.6883\u001b[0m       0.5482        0.6886  0.2617\n",
      "     17        \u001b[36m0.6882\u001b[0m       0.5482        0.6886  0.2641\n",
      "     18        \u001b[36m0.6882\u001b[0m       0.5482        0.6886  0.2639\n",
      "     19        \u001b[36m0.6881\u001b[0m       0.5482        \u001b[35m0.6886\u001b[0m  0.2656\n",
      "     20        \u001b[36m0.6881\u001b[0m       0.5482        \u001b[35m0.6886\u001b[0m  0.2637\n",
      "     21        \u001b[36m0.6880\u001b[0m       0.5482        \u001b[35m0.6886\u001b[0m  0.2618\n",
      "     22        \u001b[36m0.6879\u001b[0m       0.5482        \u001b[35m0.6886\u001b[0m  0.2624\n",
      "     23        \u001b[36m0.6879\u001b[0m       0.5482        \u001b[35m0.6886\u001b[0m  0.2648\n",
      "     24        \u001b[36m0.6878\u001b[0m       0.5482        \u001b[35m0.6886\u001b[0m  0.2617\n",
      "     25        \u001b[36m0.6878\u001b[0m       0.5482        \u001b[35m0.6886\u001b[0m  0.2635\n",
      "     26        \u001b[36m0.6878\u001b[0m       0.5482        \u001b[35m0.6886\u001b[0m  0.2634\n",
      "     27        \u001b[36m0.6877\u001b[0m       0.5482        \u001b[35m0.6885\u001b[0m  0.2634\n",
      "     28        \u001b[36m0.6877\u001b[0m       0.5482        \u001b[35m0.6885\u001b[0m  0.2625\n",
      "     29        \u001b[36m0.6877\u001b[0m       0.5482        \u001b[35m0.6885\u001b[0m  0.2633\n",
      "     30        \u001b[36m0.6876\u001b[0m       0.5482        \u001b[35m0.6885\u001b[0m  0.2684\n",
      "     31        \u001b[36m0.6876\u001b[0m       0.5482        \u001b[35m0.6885\u001b[0m  0.2713\n",
      "     32        \u001b[36m0.6876\u001b[0m       0.5482        \u001b[35m0.6885\u001b[0m  0.2699\n",
      "     33        \u001b[36m0.6876\u001b[0m       0.5482        \u001b[35m0.6885\u001b[0m  0.2777\n",
      "     34        \u001b[36m0.6876\u001b[0m       0.5482        \u001b[35m0.6885\u001b[0m  0.2756\n",
      "     35        \u001b[36m0.6875\u001b[0m       0.5482        0.6885  0.2667\n",
      "     36        \u001b[36m0.6875\u001b[0m       0.5482        0.6885  0.2684\n",
      "     37        \u001b[36m0.6875\u001b[0m       0.5482        0.6885  0.2623\n",
      "     38        \u001b[36m0.6875\u001b[0m       0.5482        0.6885  0.2646\n",
      "     39        \u001b[36m0.6874\u001b[0m       0.5475        0.6885  0.2618\n",
      "     40        \u001b[36m0.6874\u001b[0m       0.5468        0.6885  0.2679\n",
      "     41        \u001b[36m0.6874\u001b[0m       0.5468        0.6885  0.2728\n",
      "     42        \u001b[36m0.6874\u001b[0m       0.5460        0.6885  0.2725\n",
      "     43        \u001b[36m0.6874\u001b[0m       0.5460        0.6886  0.2730\n",
      "     44        \u001b[36m0.6873\u001b[0m       0.5460        0.6886  0.2780\n",
      "     45        \u001b[36m0.6873\u001b[0m       0.5460        0.6886  0.2710\n",
      "     46        \u001b[36m0.6873\u001b[0m       0.5460        0.6886  0.2745\n",
      "     47        \u001b[36m0.6873\u001b[0m       0.5460        0.6886  0.2652\n",
      "     48        \u001b[36m0.6873\u001b[0m       0.5460        0.6886  0.2669\n",
      "     49        \u001b[36m0.6872\u001b[0m       0.5460        0.6887  0.2690\n",
      "     50        \u001b[36m0.6872\u001b[0m       0.5460        0.6887  0.2634\n",
      "     51        \u001b[36m0.6872\u001b[0m       0.5460        0.6887  0.2630\n",
      "     52        \u001b[36m0.6872\u001b[0m       0.5460        0.6887  0.2618\n",
      "     53        \u001b[36m0.6872\u001b[0m       0.5460        0.6888  0.2680\n",
      "     54        \u001b[36m0.6872\u001b[0m       0.5460        0.6888  0.2630\n",
      "     55        \u001b[36m0.6871\u001b[0m       0.5460        0.6888  0.2810\n",
      "     56        \u001b[36m0.6871\u001b[0m       0.5460        0.6888  0.2660\n",
      "     57        \u001b[36m0.6871\u001b[0m       0.5460        0.6889  0.2630\n",
      "     58        \u001b[36m0.6871\u001b[0m       0.5460        0.6889  0.2629\n",
      "     59        \u001b[36m0.6871\u001b[0m       0.5460        0.6889  0.2638\n",
      "     60        \u001b[36m0.6870\u001b[0m       0.5460        0.6890  0.2661\n",
      "     61        \u001b[36m0.6870\u001b[0m       0.5460        0.6890  0.2627\n",
      "     62        \u001b[36m0.6870\u001b[0m       0.5460        0.6890  0.2642\n",
      "     63        \u001b[36m0.6870\u001b[0m       0.5460        0.6890  0.2628\n",
      "     64        \u001b[36m0.6870\u001b[0m       0.5460        0.6891  0.2642\n",
      "     65        \u001b[36m0.6869\u001b[0m       0.5460        0.6891  0.2630\n",
      "     66        \u001b[36m0.6869\u001b[0m       0.5460        0.6891  0.2638\n",
      "     67        \u001b[36m0.6869\u001b[0m       0.5460        0.6892  0.2631\n",
      "     68        \u001b[36m0.6869\u001b[0m       0.5460        0.6892  0.2672\n",
      "     69        \u001b[36m0.6869\u001b[0m       0.5460        0.6892  0.2640\n",
      "     70        \u001b[36m0.6868\u001b[0m       0.5460        0.6893  0.2632\n",
      "     71        \u001b[36m0.6868\u001b[0m       0.5460        0.6893  0.2673\n",
      "     72        \u001b[36m0.6868\u001b[0m       0.5460        0.6893  0.2641\n",
      "     73        \u001b[36m0.6868\u001b[0m       0.5460        0.6894  0.2649\n",
      "     74        \u001b[36m0.6868\u001b[0m       0.5460        0.6894  0.2634\n",
      "     75        \u001b[36m0.6867\u001b[0m       0.5460        0.6894  0.2661\n",
      "     76        \u001b[36m0.6867\u001b[0m       0.5460        0.6895  0.2636\n",
      "     77        \u001b[36m0.6867\u001b[0m       0.5460        0.6895  0.2651\n",
      "     78        \u001b[36m0.6867\u001b[0m       0.5460        0.6895  0.2646\n",
      "     79        \u001b[36m0.6867\u001b[0m       0.5460        0.6896  0.2765\n",
      "     80        \u001b[36m0.6867\u001b[0m       0.5460        0.6896  0.2748\n",
      "     81        \u001b[36m0.6866\u001b[0m       0.5460        0.6896  0.2940\n",
      "     82        \u001b[36m0.6866\u001b[0m       0.5460        0.6897  0.2736\n",
      "     83        \u001b[36m0.6866\u001b[0m       0.5460        0.6897  0.2743\n",
      "     84        \u001b[36m0.6866\u001b[0m       0.5460        0.6897  0.2714\n",
      "     85        \u001b[36m0.6866\u001b[0m       0.5460        0.6897  0.2640\n",
      "     86        \u001b[36m0.6866\u001b[0m       0.5460        0.6898  0.2670\n",
      "     87        \u001b[36m0.6865\u001b[0m       0.5460        0.6898  0.2652\n",
      "     88        \u001b[36m0.6865\u001b[0m       0.5460        0.6898  0.2652\n",
      "     89        \u001b[36m0.6865\u001b[0m       0.5460        0.6898  0.2652\n",
      "     90        \u001b[36m0.6865\u001b[0m       0.5460        0.6899  0.2772\n",
      "     91        \u001b[36m0.6865\u001b[0m       0.5460        0.6899  0.2641\n",
      "     92        \u001b[36m0.6865\u001b[0m       0.5460        0.6899  0.2650\n",
      "     93        \u001b[36m0.6864\u001b[0m       0.5460        0.6899  0.2663\n",
      "     94        \u001b[36m0.6864\u001b[0m       0.5460        0.6899  0.2654\n",
      "     95        \u001b[36m0.6864\u001b[0m       0.5460        0.6900  0.2818\n",
      "     96        \u001b[36m0.6864\u001b[0m       0.5460        0.6900  0.2651\n",
      "     97        \u001b[36m0.6864\u001b[0m       0.5460        0.6900  0.2696\n",
      "     98        \u001b[36m0.6864\u001b[0m       0.5460        0.6900  0.2656\n",
      "     99        \u001b[36m0.6864\u001b[0m       0.5460        0.6900  0.2648\n",
      "    100        \u001b[36m0.6863\u001b[0m       0.5460        0.6901  0.2654\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<class 'skorch.classifier.NeuralNetClassifier'>[initialized](\n",
       "  module_=StockPredictor(\n",
       "    (m1): Sequential(\n",
       "      (0): Linear(in_features=92, out_features=256, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Linear(in_features=256, out_features=512, bias=True)\n",
       "      (3): Sigmoid()\n",
       "      (4): Linear(in_features=512, out_features=256, bias=True)\n",
       "      (5): Sigmoid()\n",
       "      (6): Linear(in_features=256, out_features=128, bias=True)\n",
       "      (7): Sigmoid()\n",
       "      (8): Linear(in_features=128, out_features=2, bias=True)\n",
       "      (9): Softmax(dim=1)\n",
       "    )\n",
       "  ),\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = NeuralNetClassifier(\n",
    "    module=StockPredictor,\n",
    "    module__feature_size=len(cols),\n",
    "    criterion=nn.CrossEntropyLoss,\n",
    "    max_epochs=100,\n",
    "    lr=0.0001,\n",
    "    optimizer=torch.optim.Adam,\n",
    ")\n",
    "\n",
    "net.fit(X, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
